import React from "react";
import { Text } from "@consta/uikit/Text";
import { Layout } from "@consta/uikit/Layout";

const Spech = () => {
  return (
    <div className="list-grid" style={{ textAlign: "left" }}>
      <Layout direction="column" style={{ gap: "20px" }}>
        <Text size="2xl" weight="black" className="title">
          Как работает наш сервис
        </Text>
        <Text size="l" view="primary" className="paragraph">
          В нашем решении использована гибридная архитектура, позволяющая гибко
          извлекать необходимые данные на нескольких уровнях:
          <ul>
            <li>из произносимой речи на видео,</li>
            <li>из фоновой звуковой дорожки,</li>
            <li>из происходящего на видео,</li>
            <li> из пользовательского описания видео.</li>
          </ul>
          Совокупность этих данных у нас векторизуется, и с помощью поиска по
          векторной базе мы предоставляем ТОП самых подходящих под описание
          запроса видео. <br />
          Более того, наша архитектура позволяет конфигурировать веса важности
          вышеописанных данных и использовать LLM с помощью RAG (контекстные
          запросы), чтобы находить видео еще на более глубоком уровне.
        </Text>

        <Text size="l" view="primary" className="paragraph">
          <b>Преимущества нашего решения:</b> Мы используем извлечение
          уникальных кадров, которые описываем с помощью мультимодальной
          языковой модели, чтобы понять, что происходит на видео, даже если в
          нем нет описания, тегов, не произносится речь и нет фоновых звуков.
        </Text>
        <Text size="l" view="primary" className="paragraph">
          Гибкость системы позволяет управлять количеством уникальных фреймов и
          порогом уникальности, размером окна ответа LLM, использовать разные
          модальности. Векторная база позволяет оптимизировать хранение
          проиндексированных данных и ускорять по ним поиск.
        </Text>
        <Text size="l" view="primary" className="paragraph">
          <b>Описание основных алгоритмов и моделей машинного обучения:</b>
          <ul>
            <li>Алгоритмы хэширования для определения уникальности фреймов</li>
            <li>Мультимодальная языковая модель</li>
            <li>Алгоритмы векторизации</li>
            <li>RAG</li>
          </ul>
        </Text>
        <Text size="l" view="primary" className="paragraph">
          <b>Описание инструментов:</b>
          <ul>
            <li>На беке Python, FastAPI, Celery, ChromaDB for servers</li>
            <li>На фронте ReactJS, Consta.design</li>
          </ul>
        </Text>
        <Text size="l" view="primary" className="paragraph">
          <b>Скорость работы:</b>
          <ul>
            <li>
              Скорость индексации ~5 секунд на видео до 1 минуты в одном потоке
            </li>
            <li>Скорость поиска ~0.5 секунды на топ 10 видео</li>
          </ul>
        </Text>
        <Text size="l" view="primary" className="paragraph">
          Мы подошли к вопросу извлечения данных для поиска основательно и
          используем самый глубокий из возможных подходов, который даёт глубокое
          понимание о происходящем на видео и позволяет его найти, даже если по
          нему нет информации от пользователя. Мы учли баланс между скоростью
          индексирования и скоростью поиска.
        </Text>
      </Layout>
    </div>
  );
};

export default Spech;
